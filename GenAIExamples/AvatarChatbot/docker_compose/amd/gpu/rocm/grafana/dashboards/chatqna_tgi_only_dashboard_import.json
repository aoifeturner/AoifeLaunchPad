{
  "dashboard": {
    "id": null,
    "title": "AvatarChatbot TGI Dashboard (Local Development)",
    "tags": ["avatarchatbot", "tgi", "local", "development", "monitoring"],
    "timezone": "browser",
    "schemaVersion": 36,
    "version": 1,
    "refresh": "10s",
    "panels": [
      {
        "type": "row",
        "title": "System Overview",
        "gridPos": {"h": 1, "w": 24, "x": 0, "y": 0},
        "collapsed": false
      },
      {
        "type": "stat",
        "title": "Container Health",
        "datasource": "Prometheus",
        "targets": [
          {
            "expr": "up{job=\"tgi-service\"}",
            "legendFormat": "TGI Service"
          },
          {
            "expr": "up{job=\"tei-embedding\"}",
            "legendFormat": "TEI Embedding"
          },
          {
            "expr": "up{job=\"tei-reranking\"}",
            "legendFormat": "TEI Reranking"
          },
          {
            "expr": "up{job=\"retriever-tgi\"}",
            "legendFormat": "Retriever TGI"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {"mode": "thresholds"},
            "thresholds": {
              "steps": [
                {"color": "red", "value": null},
                {"color": "green", "value": 1}
              ]
            }
          }
        },
        "gridPos": {"h": 4, "w": 12, "x": 0, "y": 1}
      },
      {
        "type": "stat",
        "title": "Service Response Times",
        "datasource": "Prometheus",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job=\"tgi-service\"}[5m]))",
            "legendFormat": "TGI 95th %"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "s",
            "color": {"mode": "thresholds"},
            "thresholds": {
              "steps": [
                {"color": "green", "value": null},
                {"color": "yellow", "value": 1},
                {"color": "red", "value": 5}
              ]
            }
          }
        },
        "gridPos": {"h": 4, "w": 12, "x": 12, "y": 1}
      },
      {
        "type": "row",
        "title": "TGI (Text Generation Inference) Metrics",
        "gridPos": {"h": 1, "w": 24, "x": 0, "y": 5},
        "collapsed": false
      },
      {
        "type": "timeseries",
        "title": "TGI Request Rate",
        "datasource": "Prometheus",
        "targets": [{
          "expr": "rate(tgi_request_count[1m])",
          "legendFormat": "TGI Requests/s"
        }],
        "gridPos": {"h": 6, "w": 8, "x": 0, "y": 6}
      },
      {
        "type": "timeseries",
        "title": "TGI Success Rate",
        "datasource": "Prometheus",
        "targets": [{
          "expr": "rate(tgi_request_success[1m])",
          "legendFormat": "TGI Success/s"
        }],
        "gridPos": {"h": 6, "w": 8, "x": 8, "y": 6}
      },
      {
        "type": "timeseries",
        "title": "TGI Error Rate",
        "datasource": "Prometheus",
        "targets": [{
          "expr": "rate(tgi_request_count[1m]) - rate(tgi_request_success[1m])",
          "legendFormat": "TGI Errors/s"
        }],
        "gridPos": {"h": 6, "w": 8, "x": 16, "y": 6}
      },
      {
        "type": "timeseries",
        "title": "TGI Response Time (95th percentile)",
        "datasource": "Prometheus",
        "targets": [{
          "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job=\"tgi-service\"}[5m]))",
          "legendFormat": "TGI 95th %"
        }],
        "gridPos": {"h": 6, "w": 8, "x": 0, "y": 12}
      },
      {
        "type": "timeseries",
        "title": "TGI Response Time (50th percentile)",
        "datasource": "Prometheus",
        "targets": [{
          "expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket{job=\"tgi-service\"}[5m]))",
          "legendFormat": "TGI 50th %"
        }],
        "gridPos": {"h": 6, "w": 8, "x": 8, "y": 12}
      },
      {
        "type": "timeseries",
        "title": "TGI Response Time (99th percentile)",
        "datasource": "Prometheus",
        "targets": [{
          "expr": "histogram_quantile(0.99, rate(http_request_duration_seconds_bucket{job=\"tgi-service\"}[5m]))",
          "legendFormat": "TGI 99th %"
        }],
        "gridPos": {"h": 6, "w": 8, "x": 16, "y": 12}
      },
      {
        "type": "row",
        "title": "TEI (Text Embeddings Inference) Metrics",
        "gridPos": {"h": 1, "w": 24, "x": 0, "y": 18},
        "collapsed": false
      },
      {
        "type": "timeseries",
        "title": "TEI Embedding Request Rate",
        "datasource": "Prometheus",
        "targets": [{
          "expr": "rate(te_request_count{method=\"single\"}[1m])",
          "legendFormat": "Embedding Requests/s"
        }],
        "gridPos": {"h": 6, "w": 8, "x": 0, "y": 19}
      },
      {
        "type": "timeseries",
        "title": "TEI Embedding Success Rate",
        "datasource": "Prometheus",
        "targets": [{
          "expr": "rate(te_embed_success[1m])",
          "legendFormat": "Embedding Success/s"
        }],
        "gridPos": {"h": 6, "w": 8, "x": 8, "y": 19}
      },
      {
        "type": "timeseries",
        "title": "TEI Embedding Duration (95th percentile)",
        "datasource": "Prometheus",
        "targets": [{
          "expr": "histogram_quantile(0.95, rate(te_embed_duration_bucket[5m]))",
          "legendFormat": "95th percentile"
        }],
        "gridPos": {"h": 6, "w": 8, "x": 16, "y": 19}
      },
      {
        "type": "row",
        "title": "Resource Utilization",
        "gridPos": {"h": 1, "w": 24, "x": 0, "y": 25},
        "collapsed": false
      },
      {
        "type": "timeseries",
        "title": "TGI CPU Usage",
        "datasource": "Prometheus",
        "targets": [{
          "expr": "sum(rate(container_cpu_usage_seconds_total{container_label_com_docker_compose_service=\"tgi-service\"}[1m])) * 100",
          "legendFormat": "TGI CPU %"
        }],
        "gridPos": {"h": 6, "w": 8, "x": 0, "y": 26}
      },
      {
        "type": "timeseries",
        "title": "TEI CPU Usage",
        "datasource": "Prometheus",
        "targets": [
          {
            "expr": "sum(rate(container_cpu_usage_seconds_total{container_label_com_docker_compose_service=\"chatqna-tei-embedding-service\"}[1m])) * 100",
            "legendFormat": "TEI Embedding CPU %"
          },
          {
            "expr": "sum(rate(container_cpu_usage_seconds_total{container_label_com_docker_compose_service=\"chatqna-tei-reranking-service\"}[1m])) * 100",
            "legendFormat": "TEI Reranking CPU %"
          }
        ],
        "gridPos": {"h": 6, "w": 8, "x": 8, "y": 26}
      },
      {
        "type": "timeseries",
        "title": "System CPU Usage",
        "datasource": "Prometheus",
        "targets": [{
          "expr": "100 - (avg by (instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
          "legendFormat": "System CPU %"
        }],
        "gridPos": {"h": 6, "w": 8, "x": 16, "y": 26}
      },
      {
        "type": "timeseries",
        "title": "TGI Memory Usage",
        "datasource": "Prometheus",
        "targets": [{
          "expr": "container_memory_usage_bytes{container_label_com_docker_compose_service=\"tgi-service\"} / 1024 / 1024",
          "legendFormat": "TGI Memory MB"
        }],
        "gridPos": {"h": 6, "w": 8, "x": 0, "y": 32}
      },
      {
        "type": "timeseries",
        "title": "TEI Memory Usage",
        "datasource": "Prometheus",
        "targets": [
          {
            "expr": "container_memory_usage_bytes{container_label_com_docker_compose_service=\"chatqna-tei-embedding-service\"} / 1024 / 1024",
            "legendFormat": "TEI Embedding Memory MB"
          },
          {
            "expr": "container_memory_usage_bytes{container_label_com_docker_compose_service=\"chatqna-tei-reranking-service\"} / 1024 / 1024",
            "legendFormat": "TEI Reranking Memory MB"
          }
        ],
        "gridPos": {"h": 6, "w": 8, "x": 8, "y": 32}
      },
      {
        "type": "timeseries",
        "title": "System Memory Usage",
        "datasource": "Prometheus",
        "targets": [{
          "expr": "(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / 1024 / 1024",
          "legendFormat": "System Memory MB"
        }],
        "gridPos": {"h": 6, "w": 8, "x": 16, "y": 32}
      },
      {
        "type": "row",
        "title": "GPU Utilization (if available)",
        "gridPos": {"h": 1, "w": 24, "x": 0, "y": 38},
        "collapsed": false
      },
      {
        "type": "timeseries",
        "title": "GPU Utilization",
        "datasource": "Prometheus",
        "targets": [
          {
            "expr": "nvidia_gpu_utilization",
            "legendFormat": "GPU Utilization %"
          }
        ],
        "gridPos": {"h": 6, "w": 8, "x": 0, "y": 39}
      },
      {
        "type": "timeseries",
        "title": "GPU Memory Usage",
        "datasource": "Prometheus",
        "targets": [
          {
            "expr": "nvidia_gpu_memory_used_bytes / 1024 / 1024 / 1024",
            "legendFormat": "GPU Memory GB"
          }
        ],
        "gridPos": {"h": 6, "w": 8, "x": 8, "y": 39}
      },
      {
        "type": "timeseries",
        "title": "GPU Temperature",
        "datasource": "Prometheus",
        "targets": [
          {
            "expr": "nvidia_gpu_temperature_celsius",
            "legendFormat": "GPU Temperature Â°C"
          }
        ],
        "gridPos": {"h": 6, "w": 8, "x": 16, "y": 39}
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "timepicker": {},
    "templating": {
      "list": []
    },
    "annotations": {
      "list": []
    },
    "editable": true,
    "fiscalYearStartMonth": 0,
    "graphTooltip": 0,
    "links": [],
    "liveNow": false,
    "style": "dark"
  },
  "folderId": 0,
  "overwrite": true
} 