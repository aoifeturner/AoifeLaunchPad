version: '3.8'

services:
  whisper-service:
    image: ${REGISTRY:-opea}/whisper:${TAG:-latest}
    container_name: whisper-service
    ports:
      - "7066:7066"
    ipc: host
    environment:
      no_proxy: ${no_proxy:-}
      http_proxy: ${http_proxy:-}
      https_proxy: ${https_proxy:-}
    restart: unless-stopped
    networks:
      - rocm_default

  asr:
    image: ${REGISTRY:-opea}/asr:${TAG:-latest}
    container_name: asr-service
    ports:
      - "3001:9099"
    ipc: host
    environment:
      ASR_ENDPOINT: ${ASR_ENDPOINT}
    networks:
      - rocm_default

  speecht5-service:
    image: ${REGISTRY:-opea}/speecht5:${TAG:-latest}
    container_name: speecht5-service
    ports:
      - "7055:7055"
    ipc: host
    environment:
      no_proxy: ${no_proxy:-}
      http_proxy: ${http_proxy:-}
      https_proxy: ${https_proxy:-}
    restart: unless-stopped
    networks:
      - rocm_default

  tts:
    image: ${REGISTRY:-opea}/tts:${TAG:-latest}
    container_name: tts-service
    ports:
      - "3002:9088"
    ipc: host
    environment:
      TTS_ENDPOINT: ${TTS_ENDPOINT}
    networks:
      - rocm_default

  tgi-service:
    image: ghcr.io/huggingface/text-generation-inference:6.4.1-rocm
    container_name: tgi-service
    ports:
      - "${TGI_SERVICE_PORT:-3006}:80"
    volumes:
      - "${MODEL_CACHE:-./data}:/data"
    environment:
      no_proxy: ${no_proxy:-}
      http_proxy: ${http_proxy:-}
      https_proxy: ${https_proxy:-}
      HF_TOKEN: ${HF_TOKEN}
    shm_size: 1g
    ipc: host
    command: --model-id ${LLM_MODEL_ID} --max-input-length 4096 --max-total-tokens 8192
    networks:
      - rocm_default

  wav2lip-service:
    image: ${REGISTRY:-opea}/wav2lip:${TAG:-latest}
    container_name: wav2lip-service
    ports:
      - "7860:7860"
    ipc: host
    volumes:
      - ${PWD}:/outputs
    environment:
      no_proxy: ${no_proxy:-}
      http_proxy: ${http_proxy:-}
      https_proxy: ${https_proxy:-}
      DEVICE: ${DEVICE}
      INFERENCE_MODE: ${INFERENCE_MODE}
      CHECKPOINT_PATH: ${CHECKPOINT_PATH}
      FACE: ${FACE}
      AUDIO: ${AUDIO}
      FACESIZE: ${FACESIZE}
      OUTFILE: ${OUTFILE}
      GFPGAN_MODEL_VERSION: ${GFPGAN_MODEL_VERSION}
      UPSCALE_FACTOR: ${UPSCALE_FACTOR}
      FPS: ${FPS}
      WAV2LIP_PORT: ${WAV2LIP_PORT}
    restart: unless-stopped
    networks:
      - rocm_default

  animation:
    image: ${REGISTRY:-opea}/animation:${TAG:-latest}
    container_name: animation-server
    ports:
      - "3008:9066"
    ipc: host
    environment:
      no_proxy: ${no_proxy:-}
      http_proxy: ${http_proxy:-}
      https_proxy: ${https_proxy:-}
      WAV2LIP_ENDPOINT: ${WAV2LIP_ENDPOINT}
    restart: unless-stopped
    networks:
      - rocm_default

  avatarchatbot-backend-server:
    image: ${REGISTRY:-opea}/avatarchatbot:${TAG:-latest}
    container_name: avatarchatbot-backend-server
    depends_on:
      - asr
      - tgi-service
      - tts
      - animation
    ports:
      - "3009:8888"
    environment:
      no_proxy: ${no_proxy:-}
      https_proxy: ${https_proxy:-}
      http_proxy: ${http_proxy:-}
      MEGA_SERVICE_HOST_IP: avatarchatbot-backend-server
      MEGA_SERVICE_PORT: ${MEGA_SERVICE_PORT}
      ASR_SERVICE_HOST_IP: asr-service
      ASR_SERVICE_PORT: 9099
      LLM_SERVICE_HOST_IP: tgi-service
      LLM_SERVICE_PORT: 80
      LLM_SERVER_HOST_IP: tgi-service
      LLM_SERVER_PORT: 80
      TTS_SERVICE_HOST_IP: tts-service
      TTS_SERVICE_PORT: 9088
      ANIMATION_SERVICE_HOST_IP: animation-server
      ANIMATION_SERVICE_PORT: 9066
      WHISPER_SERVER_HOST_IP: whisper-service
      WHISPER_SERVER_PORT: 7066
      SPEECHT5_SERVER_HOST_IP: speecht5-service
      SPEECHT5_SERVER_PORT: 7055
    ipc: host
    restart: always
    networks:
      - rocm_default

networks:
  rocm_default:
    driver: bridge
